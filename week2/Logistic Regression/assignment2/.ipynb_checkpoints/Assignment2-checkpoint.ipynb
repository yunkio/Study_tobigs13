{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment2: Logistic Regression 구현\n",
    "1) 제가 제시한 틀을 사용하여 구현을 할 필요는 없습니다. 원하시는 대로 구현하시면 됩니다.  \n",
    "2) 단, code copy는 허용하지 않습니다. 코드 주석을 꼭 상세히 달아주세요. 주석이 부족한 경우, 미제출로 간주합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math, random\n",
    "from functools import partial,reduce\n",
    "from linear_algebra import *\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "data 설명\n",
    "1) Label: 유료 계정 등록 여부(target)\n",
    "2) bias: 회귀 모형에서의 상수항을 위한 term (추정 시 포함하지 않아도 ok)\n",
    "3) experience: 근속연수\n",
    "4) salary: 연봉\n",
    "\n",
    "어떤 사용자가 유료 계정을 등록할지(Label == 1)에 대한 예측을 로지스틱 회귀 모형으로 진행합니다.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('assignment_2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0. Gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def step():\n",
    "    \"\"\"\n",
    "    한 지점에서 step size만큼 이동하는 step 함수를 구현하세요.\n",
    "    필요한 인자는 3가지입니다.\n",
    "    \"\"\"\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def safe(f):\n",
    "    \"\"\"\n",
    "    f에 대한 예외처리를 위한 함수(f가 infinite일 때)\n",
    "    \"\"\"\n",
    "    def safe_f(*args, **kargs):\n",
    "        try:\n",
    "            return f(*args, **kwargs)\n",
    "        except:\n",
    "            return float('inf')\n",
    "    return safe_f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def minimize_bgd(target_fn, gradient_fn, theta_0, tolerance = 0.00001): # bgd: batch gradient descent\n",
    "    \"\"\"\n",
    "    목적함수를 최소화시키는 theta를 경사 하강법을 사용해서 찾는다.\n",
    "    \"\"\"\n",
    "    step_sizes = [100, 10, 1, 0.1, 0.01, 0.001, 0.0001, 0.00001]\n",
    "    \n",
    "    # 시작점 설정\n",
    "    theta = theta_0\n",
    "    target_fn = safe(target_fn) # 오류를 처리할 수 있는 target_fn으로 변환\n",
    "    value = target_fn(theta) # 최소화시키려는 값\n",
    "    \n",
    "    while True:\n",
    "        gradient = gradient_fn(theta) # gradient값 계산\n",
    "        next_thetas = None #### update thetas --> 각 step sizes에 따른 theta값을 list형태로 리턴\n",
    "        \n",
    "        # 함수를 최소화시키는 theta 선택\n",
    "        obj = None ## 알맞은 obj, key 값을 채워넣으세요.\n",
    "        key = None\n",
    "        next_theta = min(obj, key = key)\n",
    "        \n",
    "        # tolerance만큼 수렴하면 멈춤\n",
    "        temp = None # temp 채워넣으세요\n",
    "        if temp < tolerance:\n",
    "            return theta\n",
    "        else: #### 어떻게 업데이트 시킬지 채워넣으세요\n",
    "            pass\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stochastic():\n",
    "    \"\"\"\n",
    "    sgd 구현 (추가적인 부분이니 필수는 아닙니다.)\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. 로지스틱 함수\n",
    "해당 함수는 1/(1+exp[-(ax+b)]로 표현되었음을 기억합시다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logistic(x):\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 추가문제: softmax 구현\n",
    "def softmax():\n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. 목적함수 구현\n",
    "최적화할 목적함수를 구현합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logistic_log_likelihood_i(x_i, y_i, beta): # 개별 데이터포인트에 대한 likelihood 값\n",
    "    \"\"\"\n",
    "    None 부분을 채워서 함수를 완성하세요.\n",
    "    \"\"\"\n",
    "    cond = None\n",
    "    if cond:\n",
    "        return None\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logistic_log_likelihood(): # 전체 데이터에 대한 likelihood\n",
    "    \"\"\"\n",
    "    함수의 인자를 채워넣고,return 문을 완성하세요.\n",
    "    \"\"\"\n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Gradient for Log Reg\n",
    "아래 3가지 함수에 대해 해당 함수의 인자와 기능을 자세히 설명하세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logistic_log_partial_ij(x_i, y_i, beta, j):\n",
    "    return (y_i - logistic(dot(x_i, beta))) * x_i[j]\n",
    "\n",
    "def logistic_log_gradient_i(x_i, y_i, beta):\n",
    "    return [logistic_log_partial_ij(x_i, y_i, beta, j) for j, _ in enumerate(beta)]\n",
    "\n",
    "def logistic_log_gradient(x, y, beta):\n",
    "    return reduce(vector_add, [logistic_log_gradient_i(x_i, y_i, beta) for x_i, y_i in zip(x,y)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###설명###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Model Fitting\n",
    "위에서 구현한 목적함수와 Gradient Descent Algorithm을 이용하여 Model을 Fitting 시켜보세요.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.drop('Label', axis = 1)\n",
    "y = data['Label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(0)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 아래에 Model Fitting 진행\n",
    "# partial을 이용해 fn과 gradient_fn 구현\n",
    "\n",
    "fn = None\n",
    "gradient_fn = None\n",
    "\n",
    "beta_0 = [] # 임의의 시작점\n",
    "\n",
    "# 경사 하강법으로 최적화\n",
    "beta_hat = None"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyTorch&Tensorflow",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
