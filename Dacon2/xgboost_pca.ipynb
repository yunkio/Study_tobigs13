{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import sklearn\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from hyperopt import hp\n",
    "from hyperopt import fmin, tpe, hp, STATUS_OK, Trials\n",
    "\n",
    "import pickle\n",
    "import joblib\n",
    "\n",
    "import sys\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_train():\n",
    "    train = pd.read_csv('train.csv')\n",
    "    labels = train.type.values\n",
    "    lbl_enc = preprocessing.LabelEncoder()\n",
    "    labels = lbl_enc.fit_transform(labels)\n",
    "    train = train.drop('id', axis=1)\n",
    "    train = train.drop('fiberID', axis=1)\n",
    "    train = train.drop('type', axis=1)\n",
    "    return train.values, labels.astype('int32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_test():\n",
    "    test = pd.read_csv('test.csv')\n",
    "    test = test.drop('id', axis=1)\n",
    "    test = test.drop('fiberID', axis=1)\n",
    "    return test.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score(params):\n",
    "    print(\"Training with params : \")\n",
    "    print(params)\n",
    "    num_round = int(params['n_estimators'])\n",
    "    del params['n_estimators']\n",
    "    dtrain = xgb.DMatrix(X_train, label=y_train)\n",
    "    dvalid = xgb.DMatrix(X_test, label=y_test)\n",
    "    # watchlist = [(dvalid, 'eval'), (dtrain, 'train')]\n",
    "    model = xgb.train(params, dtrain, num_round)\n",
    "    predictions = model.predict(dvalid).reshape((X_test.shape[0], 9))\n",
    "    score = log_loss(y_test, predictions)\n",
    "    print(\"\\tScore {0}\\n\\n\".format(score))\n",
    "    return {'loss': score, 'status': STATUS_OK}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize(trials):\n",
    "    space = {\n",
    "             'eta' : hp.quniform('eta', 0.025, 0.5, 0.025),\n",
    "             'max_depth' : hp.choice('max_depth', np.arange(3, 5, dtype=int)),\n",
    "             'min_child_weight' : hp.quniform('min_child_weight', 1, 6, 1),\n",
    "             'gamma' : hp.quniform('gamma', 0.5, 1, 0.05),\n",
    "             'colsample_bytree' : hp.quniform('colsample_bytree', 0.5, 1, 0.05),\n",
    "             'num_class' : 19,\n",
    "             'eval_metric': 'mlogloss',\n",
    "             'objective': 'multi:softprob',\n",
    "             'verbosity' : 1\n",
    "             }\n",
    "\n",
    "    best = fmin(score, space, algo=tpe.suggest, trials=trials, max_evals=250)\n",
    "\n",
    "    print(best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_submission(preds, output):\n",
    "    sample = pd.read_csv('sample_submission.csv')\n",
    "    train = pd.read_csv('train.csv')\n",
    "    labels = train.type.values\n",
    "    labels = np.unique(labels)\n",
    "    preds = pd.DataFrame(\n",
    "        preds, index=sample.id.values, columns=labels)\n",
    "    preds = preds[list(sample.columns[1:])]\n",
    "    preds.to_csv(output, index_label='id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = load_train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting data into train and valid ...\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Splitting data into train and valid ...\\n\\n\")\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=1234)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PCA(copy=True, iterated_power='auto', n_components=0.8, random_state=None,\n",
       "    svd_solver='auto', tol=0.0, whiten=False)"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train, X_test = scaler.fit_transform(X_train), scaler.fit_transform(X_test) \n",
    "pca = PCA(0.8)\n",
    "pca.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_features = pca.transform(X_train)\n",
    "pca_df = pd.DataFrame(data = pca_features, columns=[\"pca1\", \"pca2\", \"pca3\", \"pca4\", \"pca5\", \"pca6\"])\n",
    "X_train = pd.DataFrame(X_train)\n",
    "X_train = pd.concat([X_train, pca_df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>pca1</th>\n",
       "      <th>pca2</th>\n",
       "      <th>pca3</th>\n",
       "      <th>pca4</th>\n",
       "      <th>pca5</th>\n",
       "      <th>pca6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.002588</td>\n",
       "      <td>0.006242</td>\n",
       "      <td>0.005500</td>\n",
       "      <td>0.006841</td>\n",
       "      <td>0.008338</td>\n",
       "      <td>0.002877</td>\n",
       "      <td>0.001180</td>\n",
       "      <td>0.004697</td>\n",
       "      <td>0.008155</td>\n",
       "      <td>0.005878</td>\n",
       "      <td>...</td>\n",
       "      <td>0.007987</td>\n",
       "      <td>0.006106</td>\n",
       "      <td>0.008560</td>\n",
       "      <td>0.011013</td>\n",
       "      <td>-0.029353</td>\n",
       "      <td>-0.005042</td>\n",
       "      <td>-0.000628</td>\n",
       "      <td>-0.001090</td>\n",
       "      <td>-0.000414</td>\n",
       "      <td>-0.000079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.002728</td>\n",
       "      <td>0.009597</td>\n",
       "      <td>0.005636</td>\n",
       "      <td>0.005216</td>\n",
       "      <td>0.004657</td>\n",
       "      <td>0.003000</td>\n",
       "      <td>0.001551</td>\n",
       "      <td>0.001261</td>\n",
       "      <td>0.003066</td>\n",
       "      <td>-0.000174</td>\n",
       "      <td>...</td>\n",
       "      <td>0.006911</td>\n",
       "      <td>0.000093</td>\n",
       "      <td>0.000301</td>\n",
       "      <td>-0.000189</td>\n",
       "      <td>-0.015283</td>\n",
       "      <td>-0.004348</td>\n",
       "      <td>0.001640</td>\n",
       "      <td>0.000292</td>\n",
       "      <td>-0.006906</td>\n",
       "      <td>0.002217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.002699</td>\n",
       "      <td>0.020642</td>\n",
       "      <td>0.029383</td>\n",
       "      <td>0.030829</td>\n",
       "      <td>0.028230</td>\n",
       "      <td>0.003083</td>\n",
       "      <td>0.003920</td>\n",
       "      <td>0.036825</td>\n",
       "      <td>0.030399</td>\n",
       "      <td>0.024335</td>\n",
       "      <td>...</td>\n",
       "      <td>0.025056</td>\n",
       "      <td>0.028007</td>\n",
       "      <td>0.031486</td>\n",
       "      <td>0.032167</td>\n",
       "      <td>-0.109840</td>\n",
       "      <td>-0.006332</td>\n",
       "      <td>-0.001155</td>\n",
       "      <td>0.005974</td>\n",
       "      <td>0.004185</td>\n",
       "      <td>-0.003611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.002838</td>\n",
       "      <td>0.027081</td>\n",
       "      <td>0.027645</td>\n",
       "      <td>0.011578</td>\n",
       "      <td>0.003690</td>\n",
       "      <td>0.003121</td>\n",
       "      <td>0.005660</td>\n",
       "      <td>0.036125</td>\n",
       "      <td>0.012728</td>\n",
       "      <td>0.002555</td>\n",
       "      <td>...</td>\n",
       "      <td>0.033313</td>\n",
       "      <td>0.025011</td>\n",
       "      <td>0.012983</td>\n",
       "      <td>0.006894</td>\n",
       "      <td>-0.077178</td>\n",
       "      <td>-0.005925</td>\n",
       "      <td>0.002343</td>\n",
       "      <td>0.011704</td>\n",
       "      <td>-0.025431</td>\n",
       "      <td>0.001155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.002617</td>\n",
       "      <td>0.003094</td>\n",
       "      <td>-0.003423</td>\n",
       "      <td>-0.001897</td>\n",
       "      <td>-0.003113</td>\n",
       "      <td>0.002890</td>\n",
       "      <td>0.000702</td>\n",
       "      <td>-0.006261</td>\n",
       "      <td>-0.002656</td>\n",
       "      <td>-0.004875</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.001582</td>\n",
       "      <td>-0.009036</td>\n",
       "      <td>-0.008606</td>\n",
       "      <td>-0.010007</td>\n",
       "      <td>0.018983</td>\n",
       "      <td>-0.004104</td>\n",
       "      <td>0.005742</td>\n",
       "      <td>0.001067</td>\n",
       "      <td>-0.003685</td>\n",
       "      <td>0.003748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>159987</td>\n",
       "      <td>0.002551</td>\n",
       "      <td>0.004081</td>\n",
       "      <td>0.003624</td>\n",
       "      <td>0.004893</td>\n",
       "      <td>0.004736</td>\n",
       "      <td>0.002462</td>\n",
       "      <td>-0.000190</td>\n",
       "      <td>-0.006120</td>\n",
       "      <td>-0.001673</td>\n",
       "      <td>-0.002697</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.006439</td>\n",
       "      <td>-0.008963</td>\n",
       "      <td>-0.007613</td>\n",
       "      <td>-0.007555</td>\n",
       "      <td>0.017032</td>\n",
       "      <td>-0.004791</td>\n",
       "      <td>0.008234</td>\n",
       "      <td>-0.003932</td>\n",
       "      <td>0.007142</td>\n",
       "      <td>0.001750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>159988</td>\n",
       "      <td>0.002586</td>\n",
       "      <td>0.006241</td>\n",
       "      <td>0.007811</td>\n",
       "      <td>0.010532</td>\n",
       "      <td>0.013100</td>\n",
       "      <td>0.002699</td>\n",
       "      <td>0.001200</td>\n",
       "      <td>0.008124</td>\n",
       "      <td>0.012177</td>\n",
       "      <td>0.011166</td>\n",
       "      <td>...</td>\n",
       "      <td>0.008080</td>\n",
       "      <td>0.008258</td>\n",
       "      <td>0.011779</td>\n",
       "      <td>0.015104</td>\n",
       "      <td>-0.039558</td>\n",
       "      <td>-0.005232</td>\n",
       "      <td>-0.000855</td>\n",
       "      <td>-0.000330</td>\n",
       "      <td>0.003721</td>\n",
       "      <td>-0.001144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>159989</td>\n",
       "      <td>0.002818</td>\n",
       "      <td>0.023875</td>\n",
       "      <td>0.025129</td>\n",
       "      <td>0.011982</td>\n",
       "      <td>0.005798</td>\n",
       "      <td>0.003472</td>\n",
       "      <td>0.005701</td>\n",
       "      <td>0.025830</td>\n",
       "      <td>0.013857</td>\n",
       "      <td>0.004008</td>\n",
       "      <td>...</td>\n",
       "      <td>0.027876</td>\n",
       "      <td>0.021939</td>\n",
       "      <td>0.013062</td>\n",
       "      <td>0.008275</td>\n",
       "      <td>-0.076384</td>\n",
       "      <td>-0.004491</td>\n",
       "      <td>0.000364</td>\n",
       "      <td>0.008958</td>\n",
       "      <td>-0.025146</td>\n",
       "      <td>0.001604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>159990</td>\n",
       "      <td>0.002828</td>\n",
       "      <td>0.026849</td>\n",
       "      <td>0.028505</td>\n",
       "      <td>0.019638</td>\n",
       "      <td>0.014473</td>\n",
       "      <td>0.003566</td>\n",
       "      <td>0.004931</td>\n",
       "      <td>0.032713</td>\n",
       "      <td>0.021769</td>\n",
       "      <td>0.013923</td>\n",
       "      <td>...</td>\n",
       "      <td>0.029706</td>\n",
       "      <td>0.024800</td>\n",
       "      <td>0.020226</td>\n",
       "      <td>0.017621</td>\n",
       "      <td>-0.094170</td>\n",
       "      <td>-0.004119</td>\n",
       "      <td>0.000574</td>\n",
       "      <td>0.005049</td>\n",
       "      <td>-0.012567</td>\n",
       "      <td>-0.001332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>159991</td>\n",
       "      <td>0.002431</td>\n",
       "      <td>-0.005214</td>\n",
       "      <td>-0.008153</td>\n",
       "      <td>-0.004065</td>\n",
       "      <td>-0.001871</td>\n",
       "      <td>0.002262</td>\n",
       "      <td>-0.001106</td>\n",
       "      <td>-0.011639</td>\n",
       "      <td>-0.003807</td>\n",
       "      <td>-0.002968</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.004032</td>\n",
       "      <td>-0.004979</td>\n",
       "      <td>-0.001582</td>\n",
       "      <td>0.000349</td>\n",
       "      <td>0.018316</td>\n",
       "      <td>-0.004392</td>\n",
       "      <td>0.000799</td>\n",
       "      <td>-0.004452</td>\n",
       "      <td>0.004462</td>\n",
       "      <td>0.001072</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>159992 rows Ã— 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               0         1         2         3         4         5         6  \\\n",
       "0       0.002588  0.006242  0.005500  0.006841  0.008338  0.002877  0.001180   \n",
       "1       0.002728  0.009597  0.005636  0.005216  0.004657  0.003000  0.001551   \n",
       "2       0.002699  0.020642  0.029383  0.030829  0.028230  0.003083  0.003920   \n",
       "3       0.002838  0.027081  0.027645  0.011578  0.003690  0.003121  0.005660   \n",
       "4       0.002617  0.003094 -0.003423 -0.001897 -0.003113  0.002890  0.000702   \n",
       "...          ...       ...       ...       ...       ...       ...       ...   \n",
       "159987  0.002551  0.004081  0.003624  0.004893  0.004736  0.002462 -0.000190   \n",
       "159988  0.002586  0.006241  0.007811  0.010532  0.013100  0.002699  0.001200   \n",
       "159989  0.002818  0.023875  0.025129  0.011982  0.005798  0.003472  0.005701   \n",
       "159990  0.002828  0.026849  0.028505  0.019638  0.014473  0.003566  0.004931   \n",
       "159991  0.002431 -0.005214 -0.008153 -0.004065 -0.001871  0.002262 -0.001106   \n",
       "\n",
       "               7         8         9  ...        16        17        18  \\\n",
       "0       0.004697  0.008155  0.005878  ...  0.007987  0.006106  0.008560   \n",
       "1       0.001261  0.003066 -0.000174  ...  0.006911  0.000093  0.000301   \n",
       "2       0.036825  0.030399  0.024335  ...  0.025056  0.028007  0.031486   \n",
       "3       0.036125  0.012728  0.002555  ...  0.033313  0.025011  0.012983   \n",
       "4      -0.006261 -0.002656 -0.004875  ... -0.001582 -0.009036 -0.008606   \n",
       "...          ...       ...       ...  ...       ...       ...       ...   \n",
       "159987 -0.006120 -0.001673 -0.002697  ... -0.006439 -0.008963 -0.007613   \n",
       "159988  0.008124  0.012177  0.011166  ...  0.008080  0.008258  0.011779   \n",
       "159989  0.025830  0.013857  0.004008  ...  0.027876  0.021939  0.013062   \n",
       "159990  0.032713  0.021769  0.013923  ...  0.029706  0.024800  0.020226   \n",
       "159991 -0.011639 -0.003807 -0.002968  ... -0.004032 -0.004979 -0.001582   \n",
       "\n",
       "              19      pca1      pca2      pca3      pca4      pca5      pca6  \n",
       "0       0.011013 -0.029353 -0.005042 -0.000628 -0.001090 -0.000414 -0.000079  \n",
       "1      -0.000189 -0.015283 -0.004348  0.001640  0.000292 -0.006906  0.002217  \n",
       "2       0.032167 -0.109840 -0.006332 -0.001155  0.005974  0.004185 -0.003611  \n",
       "3       0.006894 -0.077178 -0.005925  0.002343  0.011704 -0.025431  0.001155  \n",
       "4      -0.010007  0.018983 -0.004104  0.005742  0.001067 -0.003685  0.003748  \n",
       "...          ...       ...       ...       ...       ...       ...       ...  \n",
       "159987 -0.007555  0.017032 -0.004791  0.008234 -0.003932  0.007142  0.001750  \n",
       "159988  0.015104 -0.039558 -0.005232 -0.000855 -0.000330  0.003721 -0.001144  \n",
       "159989  0.008275 -0.076384 -0.004491  0.000364  0.008958 -0.025146  0.001604  \n",
       "159990  0.017621 -0.094170 -0.004119  0.000574  0.005049 -0.012567 -0.001332  \n",
       "159991  0.000349  0.018316 -0.004392  0.000799 -0.004452  0.004462  0.001072  \n",
       "\n",
       "[159992 rows x 26 columns]"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_features = pca.transform(X_test)\n",
    "pca_df = pd.DataFrame(data = pca_features, columns=[\"pca1\", \"pca2\", \"pca3\", \"pca4\", \"pca5\", \"pca6\"])\n",
    "X_test = pd.DataFrame(X_test)\n",
    "X_test = pd.concat([X_test, pca_df], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "trials = Trials()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimize(trials)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "xg_clf = xgb.XGBClassifier(eval_metric = 'mlogloss', objective = 'multi:softprob',colsample_bytree = 0.7, learning_rate = 0.05,\n",
    "                max_depth = 6, alpha = 10, n_estimators = 200, sub_sample=0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(alpha=10, base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=0.3, eval_metric='mlogloss',\n",
       "              gamma=0, learning_rate=0.1, max_delta_step=0, max_depth=5,\n",
       "              min_child_weight=1, missing=None, n_estimators=10, n_jobs=1,\n",
       "              nthread=None, objective='multi:softprob', random_state=0,\n",
       "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "              silent=None, subsample=1, verbosity=1)"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xg_clf.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = xg_clf.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.096285024003643"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_loss(y_test, preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub = load_test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_sub = xg_clf.predict_proba(sub)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_submission(preds_sub, \"result.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['xgb.pkl']"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(xg_clf, 'xgb.pkl') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "xg_clf = joblib.load('xgb.pkl') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'GridSearchCV' object has no attribute 'grid_scores_'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-17-b3951638c157>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m                         param_grid = param_test1, scoring=scorer,iid=False, cv=5)\n\u001b[0;32m      7\u001b[0m \u001b[0mgsearch1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[0mgsearch1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgrid_scores_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgsearch1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbest_params_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgsearch1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbest_score_\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'GridSearchCV' object has no attribute 'grid_scores_'"
     ]
    }
   ],
   "source": [
    "scorer = sklearn.metrics.make_scorer(sklearn.metrics.f1_score, average = 'weighted')\n",
    "param_test1 = {'max_depth':range(3,10,2),'min_child_weight':range(1,6,2)}\n",
    "gsearch1 = GridSearchCV(estimator = xgb.XGBClassifier( learning_rate =0.1, n_estimators=140, max_depth=5,\n",
    "                                                  min_child_weight=1, gamma=0, subsample=0.8, colsample_bytree=0.8,\n",
    "                                                  objective= 'multi:softprob', scale_pos_weight=1, seed=27, eval_metric = 'mlogloss'), \n",
    "                        param_grid = param_test1, scoring=scorer,iid=False, cv=5)\n",
    "gsearch1.fit(X_train, y_train)\n",
    "gsearch1.grid_scores_, gsearch1.best_params_, gsearch1.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'max_depth': 9, 'min_child_weight': 3}, 0.8735475931433669)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gsearch1.best_params_, gsearch1.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "({'max_depth': 9, 'min_child_weight': 3}, 0.8735475931433669)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "({'gamma': 0.1}, 0.8736117856698282)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_test3 = {\n",
    " 'gamma':[i/10.0 for i in range(0,5)]\n",
    "}\n",
    "\n",
    "scorer = sklearn.metrics.make_scorer(sklearn.metrics.f1_score, average = 'weighted')\n",
    "gsearch3 = GridSearchCV(estimator = xgb.XGBClassifier( learning_rate =0.1, n_estimators=140, max_depth=9,\n",
    "                                                  min_child_weight=3, gamma=0, subsample=0.8, colsample_bytree=0.8,\n",
    "                                                  objective= 'multi:softprob', scale_pos_weight=1,seed=27, eval_metric = 'mlogloss'), \n",
    "                        param_grid = param_test3, scoring=scorer, iid=False, cv=5)\n",
    "gsearch3.fit(X_train, y_train)\n",
    "gsearch3.best_params_, gsearch3.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "({'gamma': 0.1}, 0.8736117856698282)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'gsearch3' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-c8a487657c94>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m                         param_grid = param_test4, scoring=scorer, iid=False, cv=5)\n\u001b[0;32m     10\u001b[0m \u001b[0mgsearch4\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m \u001b[0mgsearch4\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbest_params_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgsearch3\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbest_score_\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'gsearch3' is not defined"
     ]
    }
   ],
   "source": [
    "param_test4 = {\n",
    " 'subsample':[i/10.0 for i in range(6,10)],\n",
    " 'colsample_bytree':[i/10.0 for i in range(6,10)]\n",
    "}\n",
    "scorer = sklearn.metrics.make_scorer(sklearn.metrics.f1_score, average = 'weighted')\n",
    "gsearch4 = GridSearchCV(estimator = xgb.XGBClassifier( learning_rate =0.1, n_estimators=140, max_depth=9,\n",
    "                                                  min_child_weight=3, gamma=0.1, subsample=0.8, colsample_bytree=0.8,\n",
    "                                                  objective= 'multi:softprob', scale_pos_weight=1,seed=27, eval_metric = 'mlogloss'), \n",
    "                        param_grid = param_test4, scoring=scorer, iid=False, cv=5)\n",
    "gsearch4.fit(X_train, y_train)\n",
    "gsearch4.best_params_, gsearch4.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'colsample_bytree': 0.8, 'subsample': 0.7}, 0.8736593775727819)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gsearch4.best_params_, gsearch4.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "D:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "[Parallel(n_jobs=1)]: Done  25 out of  25 | elapsed: 253.6min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "({'reg_alpha': 1e-05}, 0.8735360324514202)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_test5 = {\n",
    " 'reg_alpha':[1e-5, 1e-2, 0.1, 1, 100]\n",
    "}\n",
    "scorer = sklearn.metrics.make_scorer(sklearn.metrics.f1_score, average = 'weighted')\n",
    "gsearch5 = GridSearchCV(estimator = xgb.XGBClassifier( learning_rate =0.1, n_estimators=140, max_depth=9,\n",
    "                                                  min_child_weight=3, gamma=0.1, subsample=0.7, colsample_bytree=0.8,\n",
    "                                                  objective= 'multi:softprob', scale_pos_weight=1,seed=27, eval_metric = 'mlogloss'), \n",
    "                        param_grid = param_test5, scoring=scorer, iid=False, cv=5, verbose = 1)\n",
    "gsearch5.fit(X_train, y_train)\n",
    "gsearch5.best_params_, gsearch5.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "xg_clf = xgb.XGBClassifier( learning_rate =0.01, n_estimators=1000, max_depth=9, reg_alpha = 1e-5, \n",
    "                                                  min_child_weight=3, gamma=0.1, subsample=0.7, colsample_bytree=0.8,\n",
    "                                                  objective= 'multi:softprob', scale_pos_weight=1,seed=27, eval_metric = 'mlogloss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.9634585693419817"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xg_clf.fit(X_train,y_train)\n",
    "preds = xg_clf.predict_proba(X_test)\n",
    "log_loss(y_test, preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub = load_test()\n",
    "preds_sub = xg_clf.predict_proba(sub)\n",
    "write_submission(preds_sub, \"result.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "joblib.dump(xg_clf, 'xgb_tuned_2.pkl') \n",
    "xg_clf = joblib.load('xgb_tuned_2.pkl') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
