{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from pandas import Series, DataFrame\n",
    "from tqdm import tqdm\n",
    "\n",
    "import sklearn\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.tree.export import export_text\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.tree import export_graphviz\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "import lightgbm as lgb\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import feature_column\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('train.csv', index_col=0)\n",
    "answer = pd.read_csv('test.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>fiberID</th>\n",
       "      <th>psfMag_u</th>\n",
       "      <th>psfMag_g</th>\n",
       "      <th>psfMag_r</th>\n",
       "      <th>psfMag_i</th>\n",
       "      <th>psfMag_z</th>\n",
       "      <th>fiberMag_u</th>\n",
       "      <th>fiberMag_g</th>\n",
       "      <th>fiberMag_r</th>\n",
       "      <th>...</th>\n",
       "      <th>petroMag_u</th>\n",
       "      <th>petroMag_g</th>\n",
       "      <th>petroMag_r</th>\n",
       "      <th>petroMag_i</th>\n",
       "      <th>petroMag_z</th>\n",
       "      <th>modelMag_u</th>\n",
       "      <th>modelMag_g</th>\n",
       "      <th>modelMag_r</th>\n",
       "      <th>modelMag_i</th>\n",
       "      <th>modelMag_z</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>QSO</td>\n",
       "      <td>601</td>\n",
       "      <td>23.198224</td>\n",
       "      <td>21.431953</td>\n",
       "      <td>21.314148</td>\n",
       "      <td>21.176553</td>\n",
       "      <td>21.171444</td>\n",
       "      <td>22.581309</td>\n",
       "      <td>21.644453</td>\n",
       "      <td>21.657571</td>\n",
       "      <td>...</td>\n",
       "      <td>22.504317</td>\n",
       "      <td>21.431636</td>\n",
       "      <td>21.478312</td>\n",
       "      <td>21.145409</td>\n",
       "      <td>20.422446</td>\n",
       "      <td>22.749241</td>\n",
       "      <td>21.465534</td>\n",
       "      <td>21.364187</td>\n",
       "      <td>21.020605</td>\n",
       "      <td>21.147340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>QSO</td>\n",
       "      <td>788</td>\n",
       "      <td>21.431355</td>\n",
       "      <td>20.708104</td>\n",
       "      <td>20.678850</td>\n",
       "      <td>20.703420</td>\n",
       "      <td>20.473229</td>\n",
       "      <td>21.868797</td>\n",
       "      <td>21.029773</td>\n",
       "      <td>20.967054</td>\n",
       "      <td>...</td>\n",
       "      <td>21.360701</td>\n",
       "      <td>20.778968</td>\n",
       "      <td>20.889705</td>\n",
       "      <td>20.639812</td>\n",
       "      <td>20.646660</td>\n",
       "      <td>21.492955</td>\n",
       "      <td>20.758527</td>\n",
       "      <td>20.753925</td>\n",
       "      <td>20.693389</td>\n",
       "      <td>20.512314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>QSO</td>\n",
       "      <td>427</td>\n",
       "      <td>17.851451</td>\n",
       "      <td>16.727898</td>\n",
       "      <td>16.679677</td>\n",
       "      <td>16.694640</td>\n",
       "      <td>16.641788</td>\n",
       "      <td>18.171890</td>\n",
       "      <td>17.033098</td>\n",
       "      <td>16.999682</td>\n",
       "      <td>...</td>\n",
       "      <td>17.867253</td>\n",
       "      <td>16.738784</td>\n",
       "      <td>16.688874</td>\n",
       "      <td>16.744210</td>\n",
       "      <td>16.808006</td>\n",
       "      <td>17.818063</td>\n",
       "      <td>16.697434</td>\n",
       "      <td>16.641249</td>\n",
       "      <td>16.660177</td>\n",
       "      <td>16.688928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>QSO</td>\n",
       "      <td>864</td>\n",
       "      <td>20.789900</td>\n",
       "      <td>20.040371</td>\n",
       "      <td>19.926909</td>\n",
       "      <td>19.843840</td>\n",
       "      <td>19.463270</td>\n",
       "      <td>21.039030</td>\n",
       "      <td>20.317165</td>\n",
       "      <td>20.217898</td>\n",
       "      <td>...</td>\n",
       "      <td>20.433907</td>\n",
       "      <td>19.993727</td>\n",
       "      <td>19.985531</td>\n",
       "      <td>19.750917</td>\n",
       "      <td>19.455117</td>\n",
       "      <td>20.770711</td>\n",
       "      <td>20.001699</td>\n",
       "      <td>19.889798</td>\n",
       "      <td>19.758113</td>\n",
       "      <td>19.552855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>STAR_RED_DWARF</td>\n",
       "      <td>612</td>\n",
       "      <td>26.454969</td>\n",
       "      <td>23.058767</td>\n",
       "      <td>21.471406</td>\n",
       "      <td>19.504961</td>\n",
       "      <td>18.389096</td>\n",
       "      <td>25.700632</td>\n",
       "      <td>23.629122</td>\n",
       "      <td>21.742750</td>\n",
       "      <td>...</td>\n",
       "      <td>25.859229</td>\n",
       "      <td>22.426929</td>\n",
       "      <td>21.673551</td>\n",
       "      <td>19.610012</td>\n",
       "      <td>18.376141</td>\n",
       "      <td>24.877052</td>\n",
       "      <td>23.147993</td>\n",
       "      <td>21.475342</td>\n",
       "      <td>19.487330</td>\n",
       "      <td>18.375655</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              type  fiberID   psfMag_u   psfMag_g   psfMag_r   psfMag_i  \\\n",
       "id                                                                        \n",
       "0              QSO      601  23.198224  21.431953  21.314148  21.176553   \n",
       "1              QSO      788  21.431355  20.708104  20.678850  20.703420   \n",
       "2              QSO      427  17.851451  16.727898  16.679677  16.694640   \n",
       "3              QSO      864  20.789900  20.040371  19.926909  19.843840   \n",
       "4   STAR_RED_DWARF      612  26.454969  23.058767  21.471406  19.504961   \n",
       "\n",
       "     psfMag_z  fiberMag_u  fiberMag_g  fiberMag_r  ...  petroMag_u  \\\n",
       "id                                                 ...               \n",
       "0   21.171444   22.581309   21.644453   21.657571  ...   22.504317   \n",
       "1   20.473229   21.868797   21.029773   20.967054  ...   21.360701   \n",
       "2   16.641788   18.171890   17.033098   16.999682  ...   17.867253   \n",
       "3   19.463270   21.039030   20.317165   20.217898  ...   20.433907   \n",
       "4   18.389096   25.700632   23.629122   21.742750  ...   25.859229   \n",
       "\n",
       "    petroMag_g  petroMag_r  petroMag_i  petroMag_z  modelMag_u  modelMag_g  \\\n",
       "id                                                                           \n",
       "0    21.431636   21.478312   21.145409   20.422446   22.749241   21.465534   \n",
       "1    20.778968   20.889705   20.639812   20.646660   21.492955   20.758527   \n",
       "2    16.738784   16.688874   16.744210   16.808006   17.818063   16.697434   \n",
       "3    19.993727   19.985531   19.750917   19.455117   20.770711   20.001699   \n",
       "4    22.426929   21.673551   19.610012   18.376141   24.877052   23.147993   \n",
       "\n",
       "    modelMag_r  modelMag_i  modelMag_z  \n",
       "id                                      \n",
       "0    21.364187   21.020605   21.147340  \n",
       "1    20.753925   20.693389   20.512314  \n",
       "2    16.641249   16.660177   16.688928  \n",
       "3    19.889798   19.758113   19.552855  \n",
       "4    21.475342   19.487330   18.375655  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 데이터 준비"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.loc[:, df.columns != \"type\"]\n",
    "X = df.loc[:, X.columns != \"fiberID\"]\n",
    "y = df[\"type\"]\n",
    "answer = answer.loc[:, answer.columns != \"fiberID\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = []\n",
    "for column in list(X_train.columns)[2:]:\n",
    "    X_train = X_train[X_train[column] < 40] \n",
    "    X_train = X_train[X_train[column] > 15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "ilist = X_train.index.values.tolist()\n",
    "y_train = y_train[ilist]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "                       max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=1000,\n",
       "                       n_jobs=None, oob_score=False, random_state=0, verbose=0,\n",
       "                       warm_start=False)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forest = RandomForestClassifier(n_estimators=1000, random_state=0)\n",
    "forest.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 0.8754125137504584\n"
     ]
    }
   ],
   "source": [
    "y_pred = forest.predict(X_test)\n",
    "print('Accuracy =', accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "forest_probas = forest.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4137424103974615\n"
     ]
    }
   ],
   "source": [
    "score = sklearn.metrics.log_loss(y_test, forest_probas)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 로지스틱"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='warn', n_jobs=None, penalty='l2',\n",
       "                   random_state=77, solver='warn', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LR = LogisticRegression(random_state=77)\n",
    "LR.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 0.726957565252175\n"
     ]
    }
   ],
   "source": [
    "y_pred = LR.predict(X_test)\n",
    "print('Accuracy =', accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9174112841691602\n"
     ]
    }
   ],
   "source": [
    "LR_probas = LR.predict_proba(X_test)\n",
    "score = sklearn.metrics.log_loss(y_test, LR_probas)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LGB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgb_train = lgb.Dataset(X_train, y_train)\n",
    "lgb_eval = lgb.Dataset(X_test, y_test, reference=lgb_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgbm = lgb.LGBMClassifier(num_leaves = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,\n",
       "               importance_type='split', learning_rate=0.1, max_depth=-1,\n",
       "               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,\n",
       "               n_estimators=100, n_jobs=-1, num_leaves=100, objective=None,\n",
       "               random_state=None, reg_alpha=0.0, reg_lambda=0.0, silent=True,\n",
       "               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lgbm.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 0.7801426714223807\n"
     ]
    }
   ],
   "source": [
    "y_pred = lgbm.predict(X_test)\n",
    "print('Accuracy =', accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.206471224983855\n"
     ]
    }
   ],
   "source": [
    "LGBM_probas = lgbm.predict_proba(X_test)\n",
    "score = sklearn.metrics.log_loss(y_test, LGBM_probas)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 옹"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_probas = forest.predict_proba(answer)\n",
    "sub = pd.DataFrame(submission_probas)\n",
    "sub.columns = forest.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "forsub = pd.read_csv('sample_submission.csv')\n",
    "sub = sub.reindex(columns=list(forsub.columns))\n",
    "sub.to_csv('sub.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Autokeras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train for 3429 steps, validate for 858 steps\n",
      "Epoch 1/1000\n",
      "3429/3429 [==============================] - ETA: 27:51 - loss: 151.8574 - accuracy: 0.156 - ETA: 1:03 - loss: 74.5135 - accuracy: 0.0776  - ETA: 33s - loss: 45.0016 - accuracy: 0.126 - ETA: 23s - loss: 31.8427 - accuracy: 0.13 - ETA: 19s - loss: 24.8315 - accuracy: 0.14 - ETA: 16s - loss: 20.6007 - accuracy: 0.14 - ETA: 14s - loss: 17.6347 - accuracy: 0.15 - ETA: 13s - loss: 15.7457 - accuracy: 0.16 - ETA: 12s - loss: 14.1747 - accuracy: 0.16 - ETA: 11s - loss: 12.9663 - accuracy: 0.17 - ETA: 11s - loss: 12.0626 - accuracy: 0.17 - ETA: 10s - loss: 11.3499 - accuracy: 0.18 - ETA: 10s - loss: 10.6648 - accuracy: 0.18 - ETA: 9s - loss: 10.1621 - accuracy: 0.1897 - ETA: 9s - loss: 9.6417 - accuracy: 0.189 - ETA: 9s - loss: 9.1862 - accuracy: 0.19 - ETA: 8s - loss: 8.7574 - accuracy: 0.19 - ETA: 8s - loss: 8.3298 - accuracy: 0.19 - ETA: 8s - loss: 8.0037 - accuracy: 0.19 - ETA: 8s - loss: 7.7916 - accuracy: 0.19 - ETA: 8s - loss: 7.5490 - accuracy: 0.20 - ETA: 7s - loss: 7.3584 - accuracy: 0.20 - ETA: 7s - loss: 7.1417 - accuracy: 0.20 - ETA: 7s - loss: 6.9207 - accuracy: 0.20 - ETA: 7s - loss: 6.7044 - accuracy: 0.20 - ETA: 7s - loss: 6.5138 - accuracy: 0.20 - ETA: 6s - loss: 6.3488 - accuracy: 0.21 - ETA: 6s - loss: 6.2089 - accuracy: 0.21 - ETA: 6s - loss: 6.0749 - accuracy: 0.21 - ETA: 6s - loss: 5.9448 - accuracy: 0.21 - ETA: 6s - loss: 5.8227 - accuracy: 0.21 - ETA: 6s - loss: 5.7084 - accuracy: 0.21 - ETA: 6s - loss: 5.5938 - accuracy: 0.22 - ETA: 6s - loss: 5.4923 - accuracy: 0.22 - ETA: 5s - loss: 5.4005 - accuracy: 0.22 - ETA: 5s - loss: 5.3269 - accuracy: 0.22 - ETA: 5s - loss: 5.2461 - accuracy: 0.22 - ETA: 5s - loss: 5.1763 - accuracy: 0.22 - ETA: 5s - loss: 5.0973 - accuracy: 0.23 - ETA: 5s - loss: 5.0269 - accuracy: 0.23 - ETA: 5s - loss: 4.9519 - accuracy: 0.23 - ETA: 5s - loss: 4.8815 - accuracy: 0.23 - ETA: 5s - loss: 4.8243 - accuracy: 0.23 - ETA: 5s - loss: 4.7649 - accuracy: 0.23 - ETA: 5s - loss: 4.7081 - accuracy: 0.24 - ETA: 5s - loss: 4.6584 - accuracy: 0.24 - ETA: 4s - loss: 4.6042 - accuracy: 0.24 - ETA: 4s - loss: 4.5454 - accuracy: 0.24 - ETA: 4s - loss: 4.4960 - accuracy: 0.24 - ETA: 4s - loss: 4.4432 - accuracy: 0.24 - ETA: 4s - loss: 4.3949 - accuracy: 0.24 - ETA: 4s - loss: 4.3470 - accuracy: 0.25 - ETA: 4s - loss: 4.3068 - accuracy: 0.25 - ETA: 4s - loss: 4.2691 - accuracy: 0.25 - ETA: 4s - loss: 4.2432 - accuracy: 0.25 - ETA: 4s - loss: 4.2074 - accuracy: 0.25 - ETA: 4s - loss: 4.1683 - accuracy: 0.25 - ETA: 4s - loss: 4.1300 - accuracy: 0.25 - ETA: 3s - loss: 4.0909 - accuracy: 0.26 - ETA: 3s - loss: 4.0588 - accuracy: 0.26 - ETA: 3s - loss: 4.0232 - accuracy: 0.26 - ETA: 3s - loss: 3.9879 - accuracy: 0.26 - ETA: 3s - loss: 3.9518 - accuracy: 0.26 - ETA: 3s - loss: 3.9259 - accuracy: 0.26 - ETA: 3s - loss: 3.9002 - accuracy: 0.26 - ETA: 3s - loss: 3.8692 - accuracy: 0.27 - ETA: 3s - loss: 3.8388 - accuracy: 0.27 - ETA: 3s - loss: 3.8102 - accuracy: 0.27 - ETA: 3s - loss: 3.7815 - accuracy: 0.27 - ETA: 3s - loss: 3.7590 - accuracy: 0.27 - ETA: 3s - loss: 3.7390 - accuracy: 0.27 - ETA: 3s - loss: 3.7127 - accuracy: 0.28 - ETA: 2s - loss: 3.6872 - accuracy: 0.28 - ETA: 2s - loss: 3.6631 - accuracy: 0.28 - ETA: 2s - loss: 3.6413 - accuracy: 0.28 - ETA: 2s - loss: 3.6147 - accuracy: 0.28 - ETA: 2s - loss: 3.5903 - accuracy: 0.28 - ETA: 2s - loss: 3.5709 - accuracy: 0.28 - ETA: 2s - loss: 3.5482 - accuracy: 0.28 - ETA: 2s - loss: 3.5254 - accuracy: 0.29 - ETA: 2s - loss: 3.5039 - accuracy: 0.29 - ETA: 2s - loss: 3.4837 - accuracy: 0.29 - ETA: 2s - loss: 3.4631 - accuracy: 0.29 - ETA: 2s - loss: 3.4442 - accuracy: 0.29 - ETA: 2s - loss: 3.4227 - accuracy: 0.29 - ETA: 2s - loss: 3.4042 - accuracy: 0.29 - ETA: 2s - loss: 3.3840 - accuracy: 0.30 - ETA: 1s - loss: 3.3633 - accuracy: 0.30 - ETA: 1s - loss: 3.3427 - accuracy: 0.30 - ETA: 1s - loss: 3.3247 - accuracy: 0.30 - ETA: 1s - loss: 3.3070 - accuracy: 0.30 - ETA: 1s - loss: 3.2907 - accuracy: 0.30 - ETA: 1s - loss: 3.2749 - accuracy: 0.30 - ETA: 1s - loss: 3.2582 - accuracy: 0.31 - ETA: 1s - loss: 3.2425 - accuracy: 0.31 - ETA: 1s - loss: 3.2260 - accuracy: 0.31 - ETA: 1s - loss: 3.2102 - accuracy: 0.31 - ETA: 1s - loss: 3.1956 - accuracy: 0.31 - ETA: 1s - loss: 3.1798 - accuracy: 0.31 - ETA: 1s - loss: 3.1643 - accuracy: 0.31 - ETA: 1s - loss: 3.1484 - accuracy: 0.31 - ETA: 1s - loss: 3.1334 - accuracy: 0.31 - ETA: 1s - loss: 3.1187 - accuracy: 0.32 - ETA: 0s - loss: 3.1052 - accuracy: 0.32 - ETA: 0s - loss: 3.0916 - accuracy: 0.32 - ETA: 0s - loss: 3.0778 - accuracy: 0.32 - ETA: 0s - loss: 3.0646 - accuracy: 0.32 - ETA: 0s - loss: 3.0514 - accuracy: 0.32 - ETA: 0s - loss: 3.0385 - accuracy: 0.32 - ETA: 0s - loss: 3.0247 - accuracy: 0.32 - ETA: 0s - loss: 3.0111 - accuracy: 0.33 - ETA: 0s - loss: 2.9994 - accuracy: 0.33 - ETA: 0s - loss: 2.9864 - accuracy: 0.33 - ETA: 0s - loss: 2.9739 - accuracy: 0.33 - ETA: 0s - loss: 2.9621 - accuracy: 0.33 - ETA: 0s - loss: 2.9491 - accuracy: 0.33 - ETA: 0s - loss: 2.9362 - accuracy: 0.33 - ETA: 0s - loss: 2.9238 - accuracy: 0.33 - ETA: 0s - loss: 2.9122 - accuracy: 0.33 - 8s 2ms/step - loss: 2.9060 - accuracy: 0.3400 - val_loss: 1.7215 - val_accuracy: 0.4274\n",
      "Epoch 2/1000\n",
      "2703/3429 [======================>.......] - ETA: 3:18 - loss: 1.7768 - accuracy: 0.37 - ETA: 12s - loss: 1.7342 - accuracy: 0.4156 - ETA: 8s - loss: 1.7205 - accuracy: 0.435 - ETA: 7s - loss: 1.6707 - accuracy: 0.44 - ETA: 6s - loss: 1.6489 - accuracy: 0.45 - ETA: 6s - loss: 1.6433 - accuracy: 0.45 - ETA: 6s - loss: 1.6256 - accuracy: 0.46 - ETA: 6s - loss: 1.6161 - accuracy: 0.46 - ETA: 5s - loss: 1.6210 - accuracy: 0.46 - ETA: 6s - loss: 1.6152 - accuracy: 0.46 - ETA: 5s - loss: 1.6216 - accuracy: 0.46 - ETA: 5s - loss: 1.6145 - accuracy: 0.46 - ETA: 5s - loss: 1.6158 - accuracy: 0.46 - ETA: 5s - loss: 1.6168 - accuracy: 0.46 - ETA: 5s - loss: 1.6151 - accuracy: 0.46 - ETA: 5s - loss: 1.6158 - accuracy: 0.46 - ETA: 5s - loss: 1.6166 - accuracy: 0.46 - ETA: 5s - loss: 1.6120 - accuracy: 0.46 - ETA: 5s - loss: 1.6099 - accuracy: 0.46 - ETA: 5s - loss: 1.6092 - accuracy: 0.46 - ETA: 4s - loss: 1.6040 - accuracy: 0.46 - ETA: 4s - loss: 1.6009 - accuracy: 0.46 - ETA: 4s - loss: 1.5954 - accuracy: 0.46 - ETA: 4s - loss: 1.5924 - accuracy: 0.46 - ETA: 4s - loss: 1.5902 - accuracy: 0.46 - ETA: 4s - loss: 1.5887 - accuracy: 0.46 - ETA: 4s - loss: 1.5868 - accuracy: 0.47 - ETA: 4s - loss: 1.5878 - accuracy: 0.46 - ETA: 4s - loss: 1.5842 - accuracy: 0.47 - ETA: 4s - loss: 1.5794 - accuracy: 0.47 - ETA: 4s - loss: 1.5781 - accuracy: 0.47 - ETA: 4s - loss: 1.5747 - accuracy: 0.47 - ETA: 4s - loss: 1.5741 - accuracy: 0.47 - ETA: 4s - loss: 1.5721 - accuracy: 0.47 - ETA: 4s - loss: 1.5676 - accuracy: 0.47 - ETA: 4s - loss: 1.5646 - accuracy: 0.47 - ETA: 4s - loss: 1.5659 - accuracy: 0.47 - ETA: 4s - loss: 1.5635 - accuracy: 0.47 - ETA: 4s - loss: 1.5580 - accuracy: 0.47 - ETA: 3s - loss: 1.5557 - accuracy: 0.47 - ETA: 3s - loss: 1.5565 - accuracy: 0.47 - ETA: 3s - loss: 1.5542 - accuracy: 0.47 - ETA: 3s - loss: 1.5518 - accuracy: 0.47 - ETA: 3s - loss: 1.5518 - accuracy: 0.47 - ETA: 3s - loss: 1.5505 - accuracy: 0.47 - ETA: 3s - loss: 1.5478 - accuracy: 0.47 - ETA: 3s - loss: 1.5475 - accuracy: 0.47 - ETA: 3s - loss: 1.5463 - accuracy: 0.47 - ETA: 3s - loss: 1.5446 - accuracy: 0.48 - ETA: 3s - loss: 1.5428 - accuracy: 0.48 - ETA: 3s - loss: 1.5422 - accuracy: 0.48 - ETA: 3s - loss: 1.5429 - accuracy: 0.48 - ETA: 3s - loss: 1.5409 - accuracy: 0.48 - ETA: 3s - loss: 1.5391 - accuracy: 0.48 - ETA: 3s - loss: 1.5385 - accuracy: 0.48 - ETA: 3s - loss: 1.5379 - accuracy: 0.48 - ETA: 2s - loss: 1.5369 - accuracy: 0.48 - ETA: 2s - loss: 1.5345 - accuracy: 0.48 - ETA: 2s - loss: 1.5329 - accuracy: 0.48 - ETA: 2s - loss: 1.5307 - accuracy: 0.48 - ETA: 2s - loss: 1.5289 - accuracy: 0.48 - ETA: 2s - loss: 1.5269 - accuracy: 0.48 - ETA: 2s - loss: 1.5246 - accuracy: 0.48 - ETA: 2s - loss: 1.5222 - accuracy: 0.48 - ETA: 2s - loss: 1.5217 - accuracy: 0.48 - ETA: 2s - loss: 1.5194 - accuracy: 0.48 - ETA: 2s - loss: 1.5186 - accuracy: 0.48 - ETA: 2s - loss: 1.5173 - accuracy: 0.48 - ETA: 2s - loss: 1.5168 - accuracy: 0.48 - ETA: 2s - loss: 1.5151 - accuracy: 0.48 - ETA: 2s - loss: 1.5145 - accuracy: 0.48 - ETA: 2s - loss: 1.5131 - accuracy: 0.48 - ETA: 2s - loss: 1.5111 - accuracy: 0.48 - ETA: 2s - loss: 1.5097 - accuracy: 0.48 - ETA: 2s - loss: 1.5087 - accuracy: 0.48 - ETA: 1s - loss: 1.5082 - accuracy: 0.48 - ETA: 1s - loss: 1.5071 - accuracy: 0.48 - ETA: 1s - loss: 1.5064 - accuracy: 0.48 - ETA: 1s - loss: 1.5041 - accuracy: 0.48 - ETA: 1s - loss: 1.5033 - accuracy: 0.48 - ETA: 1s - loss: 1.5018 - accuracy: 0.48 - ETA: 1s - loss: 1.5002 - accuracy: 0.48 - ETA: 1s - loss: 1.4984 - accuracy: 0.48 - ETA: 1s - loss: 1.4977 - accuracy: 0.48 - ETA: 1s - loss: 1.4955 - accuracy: 0.48 - ETA: 1s - loss: 1.4951 - accuracy: 0.48 - ETA: 1s - loss: 1.4940 - accuracy: 0.48 - ETA: 1s - loss: 1.4923 - accuracy: 0.48 - ETA: 1s - loss: 1.4910 - accuracy: 0.49 - ETA: 1s - loss: 1.4898 - accuracy: 0.49"
     ]
    }
   ],
   "source": [
    "import autokeras as ak\n",
    "\n",
    "clf = ak.StructuredDataClassifier()\n",
    "clf.fit(X_train, y_train)\n",
    "results = clf.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
